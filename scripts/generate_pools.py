#!/usr/bin/env python3
"""Generate pool data for tokeydokey.

This script scans the tiktoken vocabulary to find tokens that can be used
to build token-efficient random identifiers using the dot/dash union strategy.

Strategy: Dot/Dash Union
- Start pool: All single-token [A-Za-z0-9]+ strings
- Next pool: All single-token [.-][A-Za-z0-9]+ strings (union of . and - prefixed)

Usage:
    uv run python scripts/generate_pools.py
    uv run python scripts/generate_pools.py --encoding cl100k_base
    uv run python scripts/generate_pools.py --out src/tokeydokey/_pools.py
"""

from __future__ import annotations

import argparse
import re
import sys
from pathlib import Path
from typing import Iterable

import tiktoken


def iter_vocab(enc: tiktoken.Encoding) -> Iterable[tuple[int, str]]:
    """Iterate through all valid tokens in the vocabulary.

    Yields tokens that:
    - Can be decoded without error
    - Encode back to the same token ID (roundtrip check)
    - Contain no whitespace
    """
    for token_id in range(enc.n_vocab):
        try:
            text = enc.decode([token_id])
        except Exception:
            continue
        try:
            encoded = enc.encode(text, disallowed_special=())
        except Exception:
            continue
        if encoded != [token_id]:
            continue
        if any(c.isspace() for c in text):
            continue
        yield token_id, text


def build_pools(
    encoding: str,
) -> tuple[list[tuple[str, int]], list[tuple[str, int]]]:
    """Build start and next pools by scanning the vocabulary.

    Returns:
        (start_pool, next_pool) where each pool is a list of (text, token_id) tuples.
    """
    enc = tiktoken.get_encoding(encoding)

    # Regex patterns for dot/dash union strategy
    start_rx = re.compile(r"^[A-Za-z0-9]+$")
    next_rx = re.compile(r"^[.-][A-Za-z0-9]+$")

    start_pool: list[tuple[str, int]] = []
    next_pool: list[tuple[str, int]] = []

    for token_id, text in iter_vocab(enc):
        if start_rx.match(text):
            start_pool.append((text, token_id))
        if next_rx.match(text):
            next_pool.append((text, token_id))

    # Sort by token_id for deterministic output
    start_pool.sort(key=lambda x: x[1])
    next_pool.sort(key=lambda x: x[1])

    return start_pool, next_pool


def write_pools_module(
    start_pool: list[tuple[str, int]],
    next_pool: list[tuple[str, int]],
    encoding: str,
    out_path: Path,
) -> None:
    """Write the pools as a Python module."""
    lines = [
        '"""Pre-generated token pools for tokeydokey.',
        "",
        "This file is auto-generated by scripts/generate_pools.py.",
        "Do not edit manually.",
        "",
        f"Encoding: {encoding}",
        f"Start pool: {len(start_pool):,} tokens",
        f"Next pool: {len(next_pool):,} tokens",
        '"""',
        "",
        f'ENCODING: str = "{encoding}"',
        "",
        "# Start tokens: alphanumeric matching ^[A-Za-z0-9]+$",
        "START: tuple[tuple[str, int], ...] = (",
    ]

    for text, token_id in start_pool:
        lines.append(f"    ({text!r}, {token_id}),")
    lines.append(")")
    lines.append("")

    lines.append("# Next tokens: dot/dash + alphanumeric matching ^[.-][A-Za-z0-9]+$")
    lines.append("NEXT: tuple[tuple[str, int], ...] = (")
    for text, token_id in next_pool:
        lines.append(f"    ({text!r}, {token_id}),")
    lines.append(")")
    lines.append("")

    out_path.write_text("\n".join(lines), encoding="utf-8")


def main(argv: list[str] | None = None) -> int:
    """Generate pool data for tokeydokey."""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--encoding",
        default="o200k_base",
        help="tiktoken encoding name (default: o200k_base)",
    )
    parser.add_argument(
        "--out",
        type=Path,
        default=Path("src/tokeydokey/_pools.py"),
        help="Output path for the pools module (default: src/tokeydokey/_pools.py)",
    )
    args = parser.parse_args(argv)

    print(f"Scanning vocabulary for encoding: {args.encoding}")
    start_pool, next_pool = build_pools(args.encoding)

    print(f"Start pool: {len(start_pool):,} tokens")
    print(f"Next pool: {len(next_pool):,} tokens")

    # Calculate combinations for reference
    n_start = len(start_pool)
    n_next = len(next_pool)
    for n_tokens in range(1, 7):
        if n_tokens == 1:
            combos = n_start
        else:
            combos = n_start * (n_next ** (n_tokens - 1))
        print(f"  {n_tokens} tokens: {combos:,} combinations")

    args.out.parent.mkdir(parents=True, exist_ok=True)
    write_pools_module(start_pool, next_pool, args.encoding, args.out)
    print(f"Wrote: {args.out}")

    return 0


if __name__ == "__main__":
    sys.exit(main())
